# Phase 06: Middle-Out Strategy Implementation — COMPLETE

**Plan:** PLAN-20260211-COMPRESSION.P06
**Completed:** 2026-02-11

## What was done

Created `packages/core/src/core/compression/MiddleOutStrategy.ts` — the middle-out
compression strategy extracted from GeminiChat's sandwich compression logic.

Updated `packages/core/src/core/compression/index.ts` to export `MiddleOutStrategy`.

## Implementation details

The `MiddleOutStrategy` class implements `CompressionStrategy` with:

- **`name: 'middle-out'`** and **`requiresLLM: true`**
- **`compress(context)`** — main entry point that:
  1. Returns original history unchanged for empty histories
  2. Computes sandwich split (top/middle/bottom) using threshold-based indices
  3. Adjusts split boundaries via `adjustForToolCallBoundary` from `./utils.js`
  4. Returns original if middle < 4 messages or boundaries overlap after adjustment
  5. Resolves compression prompt (via `promptResolver.resolveFile` with fallback to `getCompressionPrompt()`)
  6. Resolves provider via `context.resolveProvider(compressionProfile)` — profile read from ephemerals if available
  7. Builds LLM request: `[{human: prompt}, ...middleMessages, {human: triggerInstruction}]`
  8. Calls `provider.generateChatCompletion`, aggregates streamed text chunks
  9. Assembles result: `[...toKeepTop, {human: summary}, {ai: ack}, ...toKeepBottom]`
  10. Returns `CompressionResult` with complete metadata

### Private helpers

- **`computeSplit`** — replicates `getCompressionSplit()` logic from geminiChat.ts
- **`resolvePrompt`** — attempts file resolution, falls back to hardcoded prompt
- **`callProvider`** — streams and aggregates LLM response text
- **`assembleHistory`** — builds the compressed history array
- **`noCompressionResult`** — returns pass-through result with `llmCallMade: false`
- **`aggregateTextFromBlocks`** — standalone function mirroring `aggregateTextWithSpacing`

## Key decisions

- Used `readFileSync` import from `node:fs` instead of `require('node:fs')` for proper ESM typing
- `compressionProfile` accessed via type-safe cast since the ephemeral doesn't exist in the typed interface yet (future phases will add it)
- No logger.debug calls — the `Logger` class doesn't have debug method; the original code used `DebugLogger` which is a different class
- `callProvider` accepts `IProvider` directly to satisfy the overloaded `generateChatCompletion` signature
- AI acknowledgment text matches geminiChat.ts exactly: `'Got it. Thanks for the additional context!'`

## Verification

- **18/18 tests pass** — all P05 behavioral tests green
- **Typecheck clean** — `tsc --noEmit` passes for `@vybestack/llxprt-code-core`
- **No TODO/FIXME/HACK markers** in the implementation
